
<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title> ICCV 2021 Workshop: Self-supervised Learning for Next-Generation Industry-level Autonomous Driving </title>

  <link rel="canonical" href="./index.html">
  <link rel="stylesheet" href="./theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="./theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="./theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="./theme/css/style.css">
  <link rel="stylesheet" href="./theme/css/custom.css">


  <meta name="description" content="ICCV 2021 Workshop: Self-supervised Learning for Next-Generation Industry-level Autonomous Driving">
</head>

<body>
  <header class="header">
    <div class="container">
      <div class="row">
        <!-- <div class="col-xs-2">
          <a href="./">
            <img class="img-fluid" src=./images/logo.png alt="ML4H: Machine Learning for Health">
          </a>
        </div> -->
        <div class="col-xs-10">
          <h1 class="title" style="width:950px"><a href="./index.html">ICCV 2021 Workshop: Self-supervised Learning for Next-Generation Industry-level Autonomous Driving</a></h1>
          <br />
          <ul class="list-inline" style="width:max-content"> 
            <li class="list-inline-item"><a href="./index.html">Home</a></li>
            <li class="list-inline-item"><a href="./pages/call-for-participation.html">Call for Submissions</a></li>
            <li class="list-inline-item"><a href="./pages/schedule.html">Schedule</a></li>
            <li class="list-inline-item"><a href="./pages/speakers.html">Speakers</a></li>
            <li class="list-inline-item"><a href="./pages/organizers.html">Organizers</a></li>
            <li class="list-inline-item"><a href="./pages/Program Committee.html">Program Committee</a></li>
            <li class="list-inline-item"><a href="./pages/challenge.html">Challenge</a></li>
            <li class="list-inline-item"><a href="./pages/Accepted Paper.html">Accepted Papers</a></li>
          </ul>
        </div>
      </div>
    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>
</h1>

<article class="article">
  <div class="content">
    <div class="container">

<div class="row">
<!-- <div class="col-md-7"> -->
    <p>
        <!-- <b>
            ML4H 2020: a workshop at
            <a href="https://neurips.cc">NeurIPS 2020</a>
        </b> <br> -->
   Online Workshop,  October 16th, 2021
   
    
    </p>
  <!-- <p>
    Workshop Webpage: <a href='https://neurips.cc/virtual/2020/protected/workshop_16146.html'>https://neurips.cc/virtual/2020/protected/workshop_16146.html</a> -->
  <!-- <pstyle="color:grey;">Workshop Webpage -->
  </p>
    
    <p>Autonomous driving systems are posed to dramatically change society and while supervised learning approaches have given significant performance improvements in many problems (e.g. 2D detection, instance segmentation and 3D Lidar Detection) in the field of self-driving, they are notorious data hungry, requiring extensive annotation efforts. To facilitate an industry-level autonomous driving system, more label-efficient approaches are needed where visual recognition models should be equipped with the ability to self-explore, self-train and self-adapt across diverse new-appearing geographies, streets, cities, weather conditions, object labels, viewpoints or abnormal scenarios.</p> 

<p>Deviating from the traditional path of supervised learning, recent research efforts have been directed towards self-supervised learning, large-scale pretraining, weakly supervised learning and incremental/continual learning. To promote this direction, we provide a venue for discussions from both the industry and academic perspective and aim to faciliate collaborations on this topic within this workshop.</p> 


    <!-- <div></div> -->
<!-- </div> -->


    <!-- </div> -->

<!-- <div class="text"> -->
    <p>The workshop will investigate current ways of building next-generation industry level autonomous driving systems by resorting to self-supervised learning and aims to create synergies to fields that focus on learning and pretraining from limited labels (one/few/zero-shot/self-supervised learning) along/beyond autonomous driving, covering (but not limited to): </p>
    <ul>
      <li>
        Self-supervised learning techniques
      </li>
      <li>
        Life-long/incremental visual recognition methods
      </li>
      <li>
        Weakly supervised learning algorithms
      </li>
      <li>
        One/few/zero shot learning for perception tasks in self-driving
      </li>
      <li>
        Learning in the presence of noisy data
      </li>
      <li>
        Domain adaptation
      </li>
      <li>
        Weakly supervised learning for 3D Lidar and 2D images
      </li>
      <li>
        Real world self-driving image applications, e.g. lane detection, anomaly detection, object semantic segmentation/detection/localization, scene parsing, etc.
      </li>
      <li>
        Vision-based localization and tracking
      </li>
      <li>
        Safety/explainability/robustness for self-driving cars in the abovementioned settings
      </li>
    </ul>    
    <!-- <p>Apply for a <a href="https://forms.gle/SEc4Nj3RnmN6GN8e8">Travel Grant</a>.</p> -->


<p>As part of the workshop, we also release a new Self-training Self-Driving (SSD) challenge, which to the best of our knowledge is the largest of its kind. It includes three competition tasks and contains 10 million 2D images and 1 million video frames collected from real-world driving scenarios. Note, multimodal information is available for the video data, where each frame is accompanied by 1 lidar image and 6 other view angles. This SSD challenge aims to provide a standard industry-level benchmark for examining the generalization and robustness ability of self-supervised/semi-supervised perception models on large-scale real-world self-driving applications.</p>

</div>
  </div>
</article>
    </div>
  </div>

  <!-- <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">


          <li class="list-inline-item"><a href="./categories.html">Categories</a></li>

        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          <a href="https://github.com/ml4health/ml4health.github.io">
          source on github
          </a>
          /
          <a href="https://github.com/getpelican/pelican" target="_blank">powered by Pelican</a>
          /
          <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer> -->
</body>

</html>
