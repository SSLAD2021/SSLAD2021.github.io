<!DOCTYPE html>
<html lang="en">

<head>
    <title>Challenge</title>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
    <link rel="stylesheet" href="../theme/css/bootstrap.min.css">
    <link rel="stylesheet" href="../theme/css/font-awesome.min.css">
    <link rel="stylesheet" href="../theme/css/pygments/default.min.css">
    <link rel="stylesheet" href="../theme/css/style.css">
    <link rel="stylesheet" href="../theme/css/custom.css">
    <link href="../theme/fonts/icomoon/style.css" rel="stylesheet">
    <link href="../theme/css2/style.css" rel="stylesheet">

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-88572407-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body>

    <!--<body>-->
    <header class="header">
        <div class="container">
            <div class="row">
                <div class="col-xs-10">
                    <h1 class="title" style="width:950px">
                        <a href="../">
                            ICLR 2021 Workshop: Machine Learning for Preventing and Combating Pandemics
                        </a>

                    </h1>
                    <br />
                    <ul class="list-inline" style="width:max-content">
                        <li class="list-inline-item"><a href="../index.html">Home</a></li>
                        <li class="list-inline-item"><a href="../pages/call-for-participation.html">Call for
                                Submissions</a></li>
                        <li class="list-inline-item"><a href="../pages/schedule.html">Schedule</a></li>
                        <li class="list-inline-item"><a href="../pages/speakers.html">Speakers</a></li>
                        <li class="list-inline-item"><a href="../pages/organizers.html">Organizers</a></li>
                        <li class="list-inline-item"><a href="../pages/Program Committee.html">Program Committee</a>
                        </li>
                        <li class="list-inline-item"><a href="../pages/Accepted Paper.html">Accepted Papers</a></li>
                        <li class="list-inline-item"><a href="../pages/challenge.html">Challenge</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </header>
<!--<p><p><p>-->
    <br />
    <br />
    <div class="site-section">
        <div class="container">
            <div class="row middle">
                <!-- Challenge 1-->
                <div class="col-lg-12" id="challenge1">
                    <div class="section-title">
                        <h1>Track1</h1>
                        <h4>2D object detection</h4>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <p>
                                For 2D object detection and semantic segmentation, we provide a real-word training dataset with 10 million images of which 5K are labeled and with 5K/10K validation/testing labeled images for evaluation. This dataset has been collected throughout diverse scenarios in more than 30 cities in China and contains scenes in a wide variety of places, objects and weather conditions such as highways, city streets, country roads, raining weather, also different cameras / camera setups.
                            </p>

                            <ul>
                                <li><strong>Evaluation:</strong> Leaderboard ranking for this track is by Mean Average Precision (mAP) / L2 among "ALL_NS" (all Object Types), that is, the mean over the APs of pedestrians, cyclists, signs, cars, trucks, trams, tricycles, and machineshop trucks. Only camera images are allowed to be used. And we enforce a causal system, i.e, for a frame at time step t, only sensor data up to time t can be used for its prediction.</li>
                                <li><strong>Download: </strong> The training dataset is available at <a href=""> Baidu Netdisk </a> <br /></li>
                                <li><strong>Submission: </strong><a href="">submit</a> 
                                </li>
                            </ul>

                        </div>
                    </div>
                </div>


                <div class="col-lg-12" id="challenge3">
                    <div class="section-title">
                        <br />
                        <h1>Track2</h1>
                        <h4>2D semantic segmentation</h4>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <p>
                                2D semantic segmentation share the same dataset with 2D object detection.
                            </p>

                            <ul>
                                <li><strong>Evaluation:</strong> Leaderboard ranking for this track is by Mean Intersection Over Union (mIOU) among "ALL_NS" (all Object Types), that is, the mean over the IOUs of pedestrians, cyclists, signs, cars, trucks, trams, tricycles, and machineshop trucks. Only RGB sensor is allowed to be used. </li>
                                <li><strong>Download: </strong> Please download the data from <a href="">Baidu Netdisk</a>
                                </li>
                                <li><strong>Submission: </strong> <a href="">submit</a>
                            </ul>

                        </div>
                    </div>
                </div>

                <div class="col-lg-12" id="challenge3">
                    <div class="section-title">
                        <br />
                        <h1>Track3</h1>
                        <h4>multi-modality 3D object detection</h4>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <p>
                                For multi-modality object detection, we provide a large-scale training set with 1 million video frames with multi-modality information in which 5K frames are extensively labeled. Validation and test contain 3K and 8K labeled frames for evaluation. Each frame of the data consists of 1 Lidar and 7 images, extracted through multiple driving scenes in China at a frame rate of 2 fps. We provide 3D bounding boxes for car, cyclist, pedestrian, truck and bus. Data from the validation/test sets are extracted from independent scenes to ensure that no continuous frames appear in the training set.
                            </p>

                            <ul>
                                <li><strong>Evaluation:</strong> Leaderboard ranking for this track is by Mean Average Precision with Heading (mAPH) / L2 among "ALL_NS" (all Object Types except signs), that is, the mean over the APHs of car, cyclist, pedestrian, truck and bus. All sensors are allowed to be used. </li>
                                <li><strong>Download: </strong> Please download the data from <a href="">Baidu Netdisk</a>
                                </li>
                                <li><strong>Submission: </strong> <a href="">submit</a>
                            </ul>

                        </div>
                    </div>
                </div>

                <!-- Challenge 3-->
                <!-- add content -->
                <div class="col-lg-12" id="awards">
                    <br />
                    <div class="section-title">
                        <h2>Awards</h2>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
                            <p>
                                Challenge participants with the most successful and innovative entries will be invited to present at this workshop and will receive awards. A 10,000 USD cash prize will be awarded to the top performers in each task and 2nd and 3rd places will be awarded with 5 000 USD.
                            </p>
                        </div>
                    </div>
                </div>



                <!-- References -->
                <div class="col-lg-12" id="reference">
                <br />
                    <div class="section-title">
                        <h2>References</h2>
                    </div>
                    <div class="trend-entry d-flex">
                        <div class="trend-contents">
<!--                             <p>[1] Wenge Liu, Jianheng Tang, Jinghui Qin, Lin Xu, Zhen Li, Xiaodan Liang. MedDG: A
                                Large-scale Medical Consultation Dataset for Building Medical Dialogue System. Arxiv,
                                2020.</p>
                            <p>[2] Shuai Lin, Pan Zhou, Xiaodan Liang, Jianheng Tang, Ruihui Zhao, Ziliang Chen, Liang
                                Lin. Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue Generation. In AAAI,
                                2021.</p>
                            <p>[3] Suchin Gururangan, Ana MarasoviÄ‡, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,
                                Noah A. Smith. Don't Stop Pretraining: Adapt Language Models to Domains and Tasks. In ACL, 2020.
                            <p>[4] Guangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang, Sicheng Wang, Ruisi Zhang, Meng Zhou,
                                Jiaqi Zeng, Xiangyu Dong, Ruoyu Zhang, Hongchao Fang, Penghui Zhu, Shu Chen, Pengtao Xie.
                                MedDialog: Large-scale Medical Dialogue Datasets. In EMNLP, 2020.</p>
                            <p>[5] Zhongyu Wei, Qianlong Liu, Baolin Peng, Huaixiao Tou, Ting Chen, Xuanjing Huang,
                                Kam-fai Wong, Xiangying Dai. Task-oriented Dialogue System for Automatic Diagnosis. In
                                ACL, 2018.</p>
                            <p>[6] Lin Xu, Qixian Zhou, Ke Gong, Xiaodan Liang, Jianheng Tang, Liang Lin. End-to-End
                                Knowledge-Routed Relational Dialogue System for Automatic Diagnosis. In AAAI, 2019.</p>
                            <p>[7] Yuan Xia, Jingbo Zhou, Zhenhui Shi, Chao Lu, Haifeng Huang. Generative Adversarial
                                Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis. In AAAI 2020.</p> -->
                        </div>
                    </div>
                </div>

                <!-- Spanner Area Start-->
                <div class="col-lg-12 with-img" id="spanner">
                    <br />
                    <div class="section-title">
                        <h2>Sponsor</h2>
                    </div>
                    <div class="trend-entry d-flex" style="background-color: green;">
                        <!-- pic No.2 -->
<!--                         <div class="col-xs-6 col-md-4 spanner-pic-box">
                            <div class="thumbnail">
                                <a href="http://www.sysu.edu.cn/cn/index.htm">
                                    <img src="../images/sponsor/sysu.jpeg" alt="Sun Yat-sen University"
                                        class="spanner-img" align="center">
                                    <div>
                                        <h5>Sun Yat-sen University</h5>
                                    </div>
                                </a>
                            </div>
                        </div>
 -->
                        <!-- pic No.3 -->

                    </div>
                </div>
                <!-- Spanner Area End-->
                <!-- Organization Team Start-->
                <div class="col-lg-12 with-img" id="organization">
                    <br /><br />
                    <div class="section-title">
                        <h2>Organization Team</h2>
                    </div>
                    <div class="trend-entry d-flex" style="background-color: green;">
                        <!-- pic No.1 -->
<!--                         <div class="col-xs-6 col-md-3 org-pic-box">
                            <div class="thumbnail">
                                <a href="https://lemondan.github.io/">
                                    <img src="../images/challengeteam/xiaodanLiang.png" alt="XiaodanLiang" align="center"
                                        class="org-img">
                                    <div>
                                        <h6>Xiaodan Liang</h6>
                                    </div>
                                </a>
                                <p class="org-pic-description">xdliang328@gmail.com
                                    <br />
                                </p>
                            </div>
                        </div>
 -->                        <!-- pic No.6 -->
                        <!-- add content -->
                    </div>
                </div>


            </div>
        </div>
        <!-- END section -->
                    <br /><br />

    </div>
    <!-- .site-wrap -->
    <!-- loader -->
    <div class="show fullscreen" id="loader">
        <svg class="circular" height="48px" width="48px">
            <circle class="path-bg" cx="24" cy="24" fill="none" r="22" stroke="#eeeeee" stroke-width="4" />
            <circle class="path" cx="24" cy="24" fill="none" r="22" stroke="#ff5e15" stroke-miterlimit="10"
                stroke-width="4" />
        </svg>
    </div>

        <div class="footer">
            <div class="container">
                <div class="row">
                    <div class="col-12">
                        <div class="copyright">
                            <p>
                                <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                                Copyright &copy;
                                <script>document.write(new Date().getFullYear());</script>
                                All rights reserved | This template is made with <i aria-hidden="true"
                                    class="icon-heart text-danger"></i> by
                                <a href="https://colorlib.com" target="_blank" style="text-decoration: none;">Colorlib</a>
                                <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>


    <script src="../theme/js/jquery-3.3.1.min.js"></script>
    <script src="../theme/js/jquery-migrate-3.0.1.min.js"></script>
    <script src="../theme/js/jquery-ui.js"></script>
    <script src="../theme/js/popper.min.js"></script>
    <script src="../theme/js/bootstrap.min.js"></script>
    <script src="../theme/js/owl.carousel.min.js"></script>
    <script src="../theme/js/jquery.stellar.min.js"></script>
    <script src="../theme/js/jquery.countdown.min.js"></script>
    <script src="../theme/js/bootstrap-datepicker.min.js"></script>
    <script src="../theme/js/jquery.easing.1.3.js"></script>
    <script src="../theme/js/aos.js"></script>
    <script src="../theme/js/jquery.fancybox.min.js"></script>
    <script src="../theme/js/jquery.sticky.js"></script>
    <script src="../theme/js/jquery.mb.YTPlayer.min.js"></script>


    <script src="../theme/js/main.js"></script>

</body>

</html>